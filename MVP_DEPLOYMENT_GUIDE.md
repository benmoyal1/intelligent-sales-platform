# MVP Deployment Guide - Live Demo

This guide will help you deploy the AI-driven outbound call center demo for your Alta interview.

## üéØ What You'll Demonstrate

A live web application showcasing:

- ‚úÖ **Research Agent**: AI analyzes prospects using GPT-4o
- ‚úÖ **Call Simulator**: Text-based conversation showing AI reasoning
- ‚úÖ **Real-time Analysis**: Sentiment tracking and qualification
- ‚úÖ **Campaign Dashboard**: Stats and system overview

**Cost**: ~$5-10 for the entire demo

---

## üöÄ Quick Start (Local Development)

### Prerequisites

```bash
node >= 18.0.0
npm >= 9.0.0
```

### Step 1: Get OpenAI API Key

1. Go to https://platform.openai.com/api-keys
2. Create a new API key
3. Copy the key (starts with `sk-...`)

### Step 2: Setup Backend

```bash
cd backend

# Install dependencies
npm install

# Create .env file
cp .env.example .env

# Edit .env and add your OpenAI key
# OPENAI_API_KEY=sk-your-key-here

# Create data directory
mkdir -p data

# Seed database with demo data
npm run seed

# Start server
npm run dev
```

Backend will run on http://localhost:3001

### Step 3: Setup Frontend

```bash
# Open new terminal
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

Frontend will run on http://localhost:3000

### Step 4: Test It!

1. Open http://localhost:3000
2. Login with:
   - Username: `test`
   - Password: `test123`
3. Go to "Prospects" page
4. Click "Research" on a prospect (uses AI)
5. Click "Start Call" to simulate conversation

---

## üåê Production Deployment (Railway)

Railway is free for hobby projects and perfect for demos.

### Option 1: Deploy Backend to Railway

1. Create account at https://railway.app
2. Click "New Project" ‚Üí "Deploy from GitHub"
3. Select your repository
4. Railway will auto-detect Node.js
5. Add environment variables:
   ```
   OPENAI_API_KEY=sk-your-key
   JWT_SECRET=your-random-secret
   NODE_ENV=production
   ```
6. Deploy!

Railway gives you a URL like: `https://your-app.railway.app`

### Option 2: Deploy Frontend to Vercel

1. Create account at https://vercel.com
2. Click "New Project"
3. Import your git repository
4. Set root directory to `frontend`
5. Add environment variable:
   ```
   VITE_API_URL=https://your-backend.railway.app/api
   ```
6. Deploy!

Vercel gives you a URL like: `https://your-app.vercel.app`

---

## üí∞ Cost Breakdown

### OpenAI API Costs (GPT-4o-mini)

- **Research Analysis**: ~$0.001 per prospect
- **Call Conversation**: ~$0.003 per 10 messages
- **Total for demo**: ~$0.50 - $1.00

### Hosting

- **Railway**: Free tier (sufficient for demo)
- **Vercel**: Free tier (sufficient for demo)

**Total Cost**: < $5 for entire demo! üí∞

---

## üé¨ Demo Script for Interview

### 1. Login & Dashboard (1 minute)

```
"Let me show you the system dashboard. As you can see, we have:
- 8 prospects loaded
- Real-time stats on calls and meetings
- The architecture shows our multi-agent system: Research ‚Üí Call ‚Üí Booking"
```

### 2. Research Agent (2 minutes)

```
"Let's analyze a prospect. I'll click Research on Sarah Johnson...

*Wait 3-5 seconds*

The AI Research Agent just:
- Analyzed her role, company, and industry
- Generated tailored talking points
- Identified likely pain points
- Created objection handling strategies
- Calculated a success probability of [X]%

This all happened using GPT-4o with a structured prompt."
```

### 3. Call Simulator (3-4 minutes)

```
"Now let's start a simulated call. This demonstrates the AI agent's
conversation abilities without expensive voice APIs.

*Click Start Call*

The agent opens with: 'Hi, is this Sarah?...'

Let me simulate different prospect responses:

*Type: 'Yes, this is Sarah. Who is this?'*

Notice how the agent:
- Introduces itself naturally
- Uses the research insights
- Keeps responses under 3 sentences

*Type: 'I'm pretty busy right now'*

See how it handles the objection gracefully? It offers to call back.

*Type: 'Actually, I have a few minutes. What's this about?'*

Now it pivots to discovery, asking about challenges.

*Continue conversation to show BANT qualification*

The right panel shows real-time sentiment analysis and qualification status."
```

### 4. Architecture Discussion (2 minutes)

```
"The key innovation here is the multi-agent architecture:

1. Research Agent: Pre-analyzes prospects using CRM + enrichment data
2. Call Agent: Conducts intelligent conversations with context awareness
3. Booking Agent: Handles scheduling logistics

All of this uses:
- GPT-4o-mini for cost-effectiveness
- Structured prompts with JSON outputs
- Real conversation memory
- BANT qualification framework

In production, we'd replace the text simulator with real voice AI
using Twilio + OpenAI Realtime API or Vapi.ai."
```

### 5. Scaling Discussion (1 minute)

```
"This architecture scales because:
- Stateless API servers (horizontal scaling)
- Queue-based call processing
- Async AI calls
- Can handle 10,000+ calls/day with proper infrastructure

Cost per call in production: ~$0.30-0.50
Cost per booked meeting: ~$2.67
Much cheaper than human SDRs at $50+ per meeting."
```

---

## üêõ Troubleshooting

### Backend won't start

```bash
# Make sure data directory exists
mkdir -p backend/data

# Re-run seed
cd backend
npm run seed
```

### "OpenAI API error"

- Check your API key is correct in `.env`
- Verify you have credits: https://platform.openai.com/usage
- Try regenerating the key

### Frontend can't connect to backend

- Make sure backend is running on port 3001
- Check browser console for errors
- Verify proxy is working (should forward `/api` to backend)

### Database locked error

```bash
# Delete and recreate database
rm backend/data/outbound.db
cd backend
npm run seed
```

---

## üìä Demo Data

The seed script creates:

- **1 demo user**: username `demo`, password `demo123`
- **8 prospects**: Mix of different industries and roles
- **3 campaigns**: Showing various statuses

You can add more prospects by modifying `backend/src/seed-data.ts`

---

## üé® Customization Tips

### Change AI Model

Edit `backend/src/services/research-agent.ts` and `call-agent.ts`:

```typescript
model: "gpt-4o-mini"; // Change to 'gpt-4o' for better quality (more expensive)
```

### Adjust Agent Personality

Edit the system prompts in `backend/src/services/call-agent.ts`:

```typescript
PERSONALITY:
- More assertive
- More casual
- More technical
// etc.
```

### Add More Prospects

Edit `backend/src/seed-data.ts` and run:

```bash
npm run seed
```

---

## üîí Security Notes

For production (not just demo):

- Change JWT_SECRET to a strong random string
- Add rate limiting
- Enable HTTPS
- Add input validation
- Implement proper error handling

---

## üì± Mobile Support

The UI is responsive but optimized for desktop. For demo:

- Use laptop/desktop for best experience
- Screen share during virtual interview
- Or share deployed URL for them to test

---

## ‚ö° Performance Tips

To keep demo snappy:

- Uses GPT-4o-mini (fast and cheap)
- SQLite for zero-config database
- In-memory conversation state
- No external dependencies besides OpenAI

---

## üéì What to Highlight in Interview

1. **Multi-agent architecture**: Not monolithic
2. **Production thinking**: Error handling, retry logic, monitoring ready
3. **Cost-effective**: Using mini model, text instead of voice for MVP
4. **Scalable**: Queue-based, stateless, horizontally scalable
5. **GTM knowledge**: BANT framework, objection handling, call timing
6. **Modern AI patterns**: Structured outputs, function calling ready, context management

---

## üìù Common Interview Questions

**Q: Why text-based instead of real voice?**
A: "For the MVP demo, text lets us show the AI reasoning without burning budget on voice APIs. In production, we'd use Vapi.ai or Twilio + OpenAI Realtime. The agent logic is the same - we just swap the interface."

**Q: How does this scale?**
A: "The architecture is designed for scale: stateless API servers, queue-based processing, async AI calls. We can add workers horizontally. The bottleneck would be OpenAI rate limits, which we'd handle with proper tier and request batching."

**Q: What's the cost per call?**
A: "In this demo with mini model: ~$0.003 per conversation. In production with voice: ~$0.30-0.50 per call. That's 10x cheaper than human SDRs when you factor in loaded costs."

**Q: How do you ensure quality responses?**
A: "Three layers: 1) Careful prompt engineering with constraints, 2) Structured outputs with Zod schemas, 3) Human-in-the-loop review for first 100 calls to tune prompts."

---

## üöÄ Going Live Checklist

- [ ] OpenAI API key added to .env
- [ ] Backend running and seeded
- [ ] Frontend running and connected
- [ ] Test login works
- [ ] Test research on one prospect
- [ ] Test call simulation
- [ ] Prepare demo script
- [ ] Practice walkthrough (5-7 minutes)
- [ ] Have architecture diagrams ready (SOLUTION_DESIGN.md)

---

## üéâ You're Ready!

You now have a working demo that shows:

- Real AI agent reasoning
- Multi-agent architecture
- Production-quality code
- Scalable design
- GTM domain knowledge

Good luck with your Alta interview! üöÄ

---

## Support

If you run into issues:

1. Check backend logs: `npm run dev` in backend folder
2. Check frontend console: Open browser DevTools
3. Verify OpenAI API key is valid
4. Make sure you have API credits

## Next Steps After Demo

If hired, immediate improvements would be:

1. Add real voice AI integration
2. Implement vector database for semantic context
3. Add proper testing suite
4. Deploy to production environment
5. Add monitoring and analytics
6. Implement A/B testing framework
